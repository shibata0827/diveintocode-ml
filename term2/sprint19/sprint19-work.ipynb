{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 114
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3821,
     "status": "ok",
     "timestamp": 1585133985004,
     "user": {
      "displayName": "柴田祐希",
      "photoUrl": "",
      "userId": "14368319687983657863"
     },
     "user_tz": -540
    },
    "id": "LKPEpuMgpoMX",
    "outputId": "91058279-7dae-404c-99e4-f3413ae6ecd7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy  as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 729,
     "status": "ok",
     "timestamp": 1585133482380,
     "user": {
      "displayName": "柴田祐希",
      "photoUrl": "",
      "userId": "14368319687983657863"
     },
     "user_tz": -540
    },
    "id": "EAns6ZhUqG72",
    "outputId": "c5e089f1-bfc3-493c-e6c7-c2529c45de92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# 自分のマイドライブにマウントする\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 962,
     "status": "ok",
     "timestamp": 1585133985005,
     "user": {
      "displayName": "柴田祐希",
      "photoUrl": "",
      "userId": "14368319687983657863"
     },
     "user_tz": -540
    },
    "id": "HA1UJiKdqI7U",
    "outputId": "1bac83d1-53fc-474e-e0e5-ea0aaaac8906"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/sprint19\n"
     ]
    }
   ],
   "source": [
    "# カレントディレクトリの変更\n",
    "os.chdir('/content/drive/My Drive/sprint19/')\n",
    "# カレントディレクトリの取得\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8BeBuaZpmdb_"
   },
   "outputs": [],
   "source": [
    "!mkdir example_test\n",
    "!mkdir example_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6214,
     "status": "ok",
     "timestamp": 1585122019366,
     "user": {
      "displayName": "柴田祐希",
      "photoUrl": "",
      "userId": "14368319687983657863"
     },
     "user_tz": -540
    },
    "id": "fKY_SCBtn3bz",
    "outputId": "6a6b0368-d5ed-4cf3-e8e4-eec9e30ed3e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./example_train/masks’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir ./example_train/images\n",
    "!mkdir ./example_train/masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h782eSgq8W8S"
   },
   "source": [
    "# 【問題1】コードレビュー\n",
    "転移学習を使用してセグメンテーションの精度を改善したコードを提示するので、レビューを行ってください。\n",
    "\n",
    "\n",
    "《視点例》\n",
    "\n",
    "\n",
    "* 前回使用した実装とはどのように違うのか\n",
    "* 転移学習をどのように行っているか"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xU9K3gbxckE3"
   },
   "source": [
    "### 前回のUnetとの違い\n",
    "* エンコーダー部分に転移学習を行なっている\n",
    "* 今回はバッチ正則化が畳み込み層の後に行われている。\n",
    "* 評価指標は自作のIoU、ロスも自作のbce_dice_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_bXSMnP2clof"
   },
   "source": [
    "### clean-workflow-in-keras.ipynb、5. Define UNet model for training.との違い\n",
    "* unetを再帰的に表現している\n",
    "* ダウンサンプリングまでを１ブロックとして、デーコーダー時に再帰で読み出している"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QjXIi2P78beg"
   },
   "source": [
    "# 【問題2】コードの書き換え\n",
    "エンコーダーにResNetが使用されていたコードをVGGに変更してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H_4vZPzF7jh3"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.callbacks import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.applications.vgg19 import VGG19, preprocess_input\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vRHkDLhs8e-X"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "# plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d1oYW33e8h8f"
   },
   "outputs": [],
   "source": [
    "def compute_coverage(df, masks):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    def cov_to_class(val):\n",
    "        for i in range(0, 11):\n",
    "            if val * 10 <= i:\n",
    "                return i\n",
    "\n",
    "    # Output percentage of area covered by class\n",
    "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
    "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
    "    # because each coverage will occur only once.\n",
    "    df['coverage_class'] = df.coverage.map(\n",
    "        cov_to_class)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_depth_abs_channels(image_tensor):\n",
    "    image_tensor = image_tensor.astype(np.float32)\n",
    "    h, w, c = image_tensor.shape\n",
    "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
    "        image_tensor[row, :, 1] = const\n",
    "    image_tensor[:, :, 2] = (\n",
    "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
    "\n",
    "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
    "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
    "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 798,
     "status": "ok",
     "timestamp": 1585133999113,
     "user": {
      "displayName": "柴田祐希",
      "photoUrl": "",
      "userId": "14368319687983657863"
     },
     "user_tz": -540
    },
    "id": "Mo2c1AO58mqv",
    "outputId": "cd52e080-88a9-4bb0-ecd7-c89c53968c48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "           id                                           rle_mask\n",
      "0  575d24d81d                                                NaN\n",
      "1  a266a2a9df                                          5051 5151\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...\n",
      "\n",
      "test:\n",
      "           id rle_mask\n",
      "0  155410d6fa      1 1\n",
      "1  78b32781d1      1 1\n",
      "2  63db2a476a      1 1\n",
      "3  17bfcdb967      1 1\n",
      "4  7ea0fd3c88      1 1\n",
      "\n",
      "           id                                           rle_mask    z\n",
      "0  575d24d81d                                                NaN  843\n",
      "1  a266a2a9df                                          5051 5151  794\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../sprint18/train.csv')\n",
    "test = pd.read_csv('../sprint18/sample_submission.csv')\n",
    "depth = pd.read_csv('../sprint18/depths.csv')\n",
    "\n",
    "train_src = '../sprint18/gitcode/data/membrane/train/'\n",
    "\n",
    "print('train:\\n{}'.format(train.head()))\n",
    "print('\\ntest:\\n{}'.format(test.head()))\n",
    "\n",
    "\n",
    "train = train.merge(depth, how='left', on='id')\n",
    "test = test.merge(depth, how='left', on='id')\n",
    "\n",
    "print('\\n{}'.format(train.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18993,
     "status": "ok",
     "timestamp": 1585134020138,
     "user": {
      "displayName": "柴田祐希",
      "photoUrl": "",
      "userId": "14368319687983657863"
     },
     "user_tz": -540
    },
    "id": "99mY2xSW8vjR",
    "outputId": "39f7bc53-a983-4717-a18f-e0cbcc7c9057"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 101, 101) (4000, 101, 101)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.load('./example_train/images/X_train_array.npy')\n",
    "y_train = np.load('./example_train/masks/y_train_array.npy')\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1575,
     "status": "ok",
     "timestamp": 1585134029445,
     "user": {
      "displayName": "柴田祐希",
      "photoUrl": "",
      "userId": "14368319687983657863"
     },
     "user_tz": -540
    },
    "id": "YfEnC3TU8xAA",
    "outputId": "c7938f9a-49c0-4522-ab23-7a7dd0804226"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f274410ff98>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAFSCAYAAAAJl+KKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_index = np.random.randint(0, X_train.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].imshow(X_train[random_index], cmap='gray')\n",
    "ax[1].imshow(y_train[random_index], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WlaY23Uy811S"
   },
   "outputs": [],
   "source": [
    "train = compute_coverage(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19844,
     "status": "ok",
     "timestamp": 1585134059489,
     "user": {
      "displayName": "柴田祐希",
      "photoUrl": "",
      "userId": "14368319687983657863"
     },
     "user_tz": -540
    },
    "id": "PUgJaLiC82R-",
    "outputId": "348f8d36-5952-4ad5-fdcb-10d717222b26"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 101, 101, 3)\n",
      "(4000, 101, 101, 3)\n",
      "(3200, 224, 224, 3) (3200, 224, 224, 1)\n",
      "(800, 224, 224, 3) (800, 224, 224, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=1337)\n",
    "\n",
    "# Add channel features\n",
    "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n",
    "print(X_train_ch.shape)\n",
    "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
    "print(X_train_ch.shape)\n",
    "\n",
    "# Resize to 224x224, default ResNet50 image size\n",
    "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
    "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
    "\n",
    "\n",
    "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
    "    \n",
    "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
    "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
    "    \n",
    "    break\n",
    "    \n",
    "\n",
    "y_tr = np.expand_dims(y_tr, axis=-1)\n",
    "y_val = np.expand_dims(y_val, axis=-1)\n",
    "\n",
    "print(X_tr.shape, y_tr.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "del X_train_ch, y_resized\n",
    "del X_resized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "00fYxTED84iP"
   },
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "# Dice & combined\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# IoU metric for observation during training\n",
    "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
    "def get_iou_vector(A, B):\n",
    "    # Numpy version    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric\n",
    "\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "\n",
    "# For Lovash loss\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19959,
     "status": "ok",
     "timestamp": 1585134086016,
     "user": {
      "displayName": "柴田祐希",
      "photoUrl": "",
      "userId": "14368319687983657863"
     },
     "user_tz": -540
    },
    "id": "6BLuzrYA8-1o",
    "outputId": "1cad1859-c992-4505-e23c-fd619832405e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "input_size = (224, 224, 3)\n",
    "base_model = ResNet50(input_shape=input_size, include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1087,
     "status": "ok",
     "timestamp": 1585134102400,
     "user": {
      "displayName": "柴田祐希",
      "photoUrl": "",
      "userId": "14368319687983657863"
     },
     "user_tz": -540
    },
    "id": "Pa2Rlt-35027",
    "outputId": "2f200fc8-6071-48e5-89c2-00f470ee1b8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.core.Activation object at 0x7f274416e080>\n",
      "Tensor(\"activation_1/Relu:0\", shape=(?, 112, 112, 64), dtype=float32)\n",
      "<keras.layers.core.Activation object at 0x7f274416e080>\n",
      "Tensor(\"activation_1/Relu:0\", shape=(?, 112, 112, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(base_model.layers[4])\n",
    "print(base_model.layers[4].output)\n",
    "print(base_model.get_layer('activation_1'))\n",
    "print(base_model.get_layer('activation_1').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 955
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3893,
     "status": "ok",
     "timestamp": 1585134108121,
     "user": {
      "displayName": "柴田祐希",
      "photoUrl": "",
      "userId": "14368319687983657863"
     },
     "user_tz": -540
    },
    "id": "0h4b2yzQyIb-",
    "outputId": "a48d5288-d4a1-47dd-cff7-1c28e2356614"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# VGG19\n",
    "K.clear_session()\n",
    "input_size = (224, 224, 3)\n",
    "base_model = VGG19(input_shape=input_size, include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "roHFuQYA9EIU"
   },
   "outputs": [],
   "source": [
    "# Basic decoder block with Conv, BN and PReLU activation.\n",
    "def decoder_block_simple(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3)):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation'.format(block_name))(x_dec)\n",
    "\n",
    "    return x_dec\n",
    "\n",
    "# Decoder block with bottleneck architecture, where middle conv layer\n",
    "# is half the size of first and last, in order to compress representation.\n",
    "# This type of architecture is supposed to retain most useful information.\n",
    "def decoder_block_bottleneck(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3),\n",
    "        dropout_frac=0.2):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv1'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn1'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation1'.format(block_name))(x_dec)\n",
    "    x_dec = Dropout(dropout_frac)(x_dec)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters // 2, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv2'.format(block_name))(x_dec)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Add()([x_dec, x_dec2])\n",
    "\n",
    "    return x_dec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6anuWXqF9NpM"
   },
   "outputs": [],
   "source": [
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "def unet_resnet(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    base_model = ResNet50(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_model.get_layer('activation_1').output\n",
    "    encoder2 = base_model.get_layer('activation_10').output\n",
    "    encoder3 = base_model.get_layer('activation_22').output\n",
    "    encoder4 = base_model.get_layer('activation_40').output\n",
    "    encoder5 = base_model.get_layer('activation_49').output\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10344,
     "status": "ok",
     "timestamp": 1585134143569,
     "user": {
      "displayName": "柴田祐希",
      "photoUrl": "",
      "userId": "14368319687983657863"
     },
     "user_tz": -540
    },
    "id": "VnaG4kcL9Qgl",
    "outputId": "a28b3631-0a9a-42a6-fcc3-a4d0a4694247"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From <ipython-input-13-910567864b2d>:153: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "center_conv (Conv2D)            (None, 7, 7, 512)    9437696     activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           center_activation[0][0]          \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv (Conv2D)          (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv (Conv2D)          (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv (Conv2D)          (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv (Conv2D)          (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 42,912,065\n",
      "Trainable params: 42,856,833\n",
      "Non-trainable params: 55,232\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "\n",
    "K.clear_session()\n",
    "model = unet_resnet(\n",
    "    input_size, decoder_block_simple, weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3_lk0YNGBfsI"
   },
   "outputs": [],
   "source": [
    "# unet_vgg19\n",
    "def unet_vgg19(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    base_model = VGG19(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    # 最後はpoolで調整？\n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_model.get_layer('block2_conv1').output\n",
    "    encoder2 = base_model.get_layer('block3_conv1').output\n",
    "    encoder3 = base_model.get_layer('block4_conv1').output\n",
    "    encoder4 = base_model.get_layer('block5_conv1').output\n",
    "    encoder5 = base_model.get_layer('block5_pool').output\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2759,
     "status": "ok",
     "timestamp": 1585134154735,
     "user": {
      "displayName": "柴田祐希",
      "photoUrl": "",
      "userId": "14368319687983657863"
     },
     "user_tz": -540
    },
    "id": "Kke_eN4KCJfe",
    "outputId": "345ecb7f-e5b2-4065-ddea-2f29733e8a09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv4 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv4 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv4 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv (Conv2D)            (None, 7, 7, 512)    2359808     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 1024)   0           center_activation[0][0]          \n",
      "                                                                 block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv (Conv2D)          (None, 7, 7, 256)    2359552     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 768)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv (Conv2D)          (None, 14, 14, 128)  884864      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv (Conv2D)          (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv (Conv2D)          (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 192 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 192 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 55328       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 28,160,513\n",
      "Trainable params: 28,158,401\n",
      "Non-trainable params: 2,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nput_size = (224, 224, 3)\n",
    "\n",
    "K.clear_session()\n",
    "model = unet_vgg19(\n",
    "    input_size, decoder_block_simple, weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 257499,
     "status": "ok",
     "timestamp": 1585134417903,
     "user": {
      "displayName": "柴田祐希",
      "photoUrl": "",
      "userId": "14368319687983657863"
     },
     "user_tz": -540
    },
    "id": "hHMHIpz19UWU",
    "outputId": "452e70ba-7532-40bb-e9ac-cc29643c05ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 7, 7, 512)    9437696     activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           add_17[0][0]                     \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 48,978,353\n",
      "Trainable params: 48,919,953\n",
      "Non-trainable params: 58,400\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/2\n",
      "3200/3200 [==============================] - 94s 29ms/step - loss: 0.7523 - my_iou_metric: 0.3354 - val_loss: 2.7013 - val_my_iou_metric: 0.0726\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.07263, saving model to unet_resnet.h5\n",
      "Epoch 2/2\n",
      "3200/3200 [==============================] - 63s 20ms/step - loss: 0.5470 - my_iou_metric: 0.5019 - val_loss: 0.4195 - val_my_iou_metric: 0.5616\n",
      "\n",
      "Epoch 00002: val_my_iou_metric improved from 0.07263 to 0.56163, saving model to unet_resnet.h5\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "model_depth = unet_resnet(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "print(model_depth.summary())\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "epochs = 2  # 25\n",
    "batch_size = 16\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gwRtgUnTwsUP"
   },
   "outputs": [],
   "source": [
    "val_preds = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pf-7WLxE9bim"
   },
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 51533,
     "status": "ok",
     "timestamp": 1585134542280,
     "user": {
      "displayName": "柴田祐希",
      "photoUrl": "",
      "userId": "14368319687983657863"
     },
     "user_tz": -540
    },
    "id": "hV1VOGO39fgL",
    "outputId": "e0d4c179-6795-4097-ec9d-dc0df98b660a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:50<00:00,  1.44s/it]\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1088,
     "status": "ok",
     "timestamp": 1585134561964,
     "user": {
      "displayName": "柴田祐希",
      "photoUrl": "",
      "userId": "14368319687983657863"
     },
     "user_tz": -540
    },
    "id": "oKeFMfpo9iDR",
    "outputId": "0d4e68c3-c78b-408a-d775-50f80635da59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.6534 at threshold: 0.880\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.586236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.050070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.490750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.551250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.588375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.631000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.653375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.586236\n",
       "std     0.204939   0.050070\n",
       "min     0.200000   0.490750\n",
       "25%     0.370000   0.551250\n",
       "50%     0.540000   0.588375\n",
       "75%     0.710000   0.631000\n",
       "max     0.880000   0.653375"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 588
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1228,
     "status": "ok",
     "timestamp": 1585134567078,
     "user": {
      "displayName": "柴田祐希",
      "photoUrl": "",
      "userId": "14368319687983657863"
     },
     "user_tz": -540
    },
    "id": "OjH-gofV9lh5",
    "outputId": "4af9d902-fc49-4935-c2f3-1095fd4648f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f26b7a79208>"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAIWCAYAAAClXRAXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWZIkSSpjSZYkSZLKWJIlSZKkMv8HjBdqXLofVyEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zJOEdQp4UQIh"
   },
   "source": [
    "# 【問題3】学習・推定\n",
    "ResNetとVGG双方のコードで学習・推定を行い、結果を比較してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 169582,
     "status": "ok",
     "timestamp": 1585134745571,
     "user": {
      "displayName": "柴田祐希",
      "photoUrl": "",
      "userId": "14368319687983657863"
     },
     "user_tz": -540
    },
    "id": "fAnJtt-3RKLm",
    "outputId": "426dddaa-853b-4546-e990-a83d75c4b1bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv4 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv4 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv4 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 7, 7, 512)    2359808     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 1024)   0           add_1[0][0]                      \n",
      "                                                                 block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    2359552     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 768)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  884864      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 192 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 192 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 55328       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 34,226,801\n",
      "Trainable params: 34,221,521\n",
      "Non-trainable params: 5,280\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/2\n",
      "3200/3200 [==============================] - 77s 24ms/step - loss: 0.9724 - my_iou_metric: 0.1343 - val_loss: 6.0958 - val_my_iou_metric: 0.1329\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.13287, saving model to unet_resnet.h5\n",
      "Epoch 2/2\n",
      "3200/3200 [==============================] - 67s 21ms/step - loss: 0.7685 - my_iou_metric: 0.1861 - val_loss: 3.3988 - val_my_iou_metric: 0.1637\n",
      "\n",
      "Epoch 00002: val_my_iou_metric improved from 0.13287 to 0.16375, saving model to unet_resnet.h5\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "model_depth = unet_vgg19(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "print(model_depth.summary())\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "epochs = 2  # 25\n",
    "batch_size = 16\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ht1er43sR-kw"
   },
   "outputs": [],
   "source": [
    "val_preds = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 53523,
     "status": "ok",
     "timestamp": 1585134843354,
     "user": {
      "displayName": "柴田祐希",
      "photoUrl": "",
      "userId": "14368319687983657863"
     },
     "user_tz": -540
    },
    "id": "CSHylnGbSEzO",
    "outputId": "7bcc2b3a-aa71-48d4-b900-09fef92b0bec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:52<00:00,  1.50s/it]\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1095,
     "status": "ok",
     "timestamp": 1585134848681,
     "user": {
      "displayName": "柴田祐希",
      "photoUrl": "",
      "userId": "14368319687983657863"
     },
     "user_tz": -540
    },
    "id": "uaVgx3oTSd2f",
    "outputId": "e0543d21-6699-42bc-a2b3-94bba460933c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.3494 at threshold: 0.360\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.325411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.016411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.285500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.316688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.329500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.336750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.349375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.325411\n",
       "std     0.204939   0.016411\n",
       "min     0.200000   0.285500\n",
       "25%     0.370000   0.316688\n",
       "50%     0.540000   0.329500\n",
       "75%     0.710000   0.336750\n",
       "max     0.880000   0.349375"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 588
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1239,
     "status": "ok",
     "timestamp": 1585134851651,
     "user": {
      "displayName": "柴田祐希",
      "photoUrl": "",
      "userId": "14368319687983657863"
     },
     "user_tz": -540
    },
    "id": "FeMfIkRYSmo2",
    "outputId": "c282e604-f926-4c51-cd14-bca528c6f2b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f26b7a426a0>"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAIWCAYAAAClXRAXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1058,
     "status": "ok",
     "timestamp": 1585124242758,
     "user": {
      "displayName": "柴田祐希",
      "photoUrl": "",
      "userId": "14368319687983657863"
     },
     "user_tz": -540
    },
    "id": "CtyxhRf89pvf",
    "outputId": "2132f11f-12ab-4054-9643-804840a0394a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.int32(0.7 > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6M-h5yrU9xYT"
   },
   "outputs": [],
   "source": [
    "def get_iou_vector(A, B):\n",
    "    # Numpy version\n",
    "    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HRGOnUoE9zt8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMM8RDQOFPMGL5GpvmeSyyq",
   "collapsed_sections": [],
   "name": "sprint19-work.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
